{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14685dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load https://raw.githubusercontent.com/zhoudanxie/analyzing-public-comments/master/Retrieve%20Comments/GetComments.py\n",
    "#-----------------------------------------Retrieve Comments from Regulations.gov---------------------------------------#\n",
    "#---------------------------------------------The GW Regulatory Studies Center-----------------------------------------#\n",
    "#--------------------------------------------------Author: Zhoudan Xie-------------------------------------------------#\n",
    "\n",
    "# Import packages\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------\n",
    "#--------------------------------------------Get comments by Document ID------------------------------------------------\n",
    "\n",
    "docketFile='Retrieve Comments/DocketExample.csv'    #! Specify the path of your docket metadata file exported from Regulation.gov\n",
    "docket = pd.read_csv(docketFile,skiprows=4)\n",
    "docket=docket[docket['Document Type']=='PUBLIC SUBMISSIONS']\n",
    "\n",
    "APIkey=\"YOUR API KEY\"   #! Add your API key here\n",
    "\n",
    "#------------------------------------------Retrieve text comments-------------------------------------------------------\n",
    "\n",
    "saveFile='Retrieve Comments/Text Comments Example.csv'   #! Specify the path and name of the file you want to save the text comments as\n",
    "\n",
    "if os.path.isfile(saveFile):\n",
    "    commentsRetrieved=pd.read_csv(saveFile)\n",
    "    dic_comments=commentsRetrieved.set_index('Document ID')['Text Comment'].T.to_dict()\n",
    "else:\n",
    "    dic_comments = {}\n",
    "\n",
    "baseURL = \"https://api.data.gov:443/regulations/v3/document.json?api_key=\"+APIkey+\"&documentId=\"\n",
    "commentCount=len(docket['Document ID'])     # It may take a long time if you are requesting a large number of comments\n",
    "print(\"Total number of text comments you are requesting is:\", commentCount)\n",
    "\n",
    "while len(dic_comments)<commentCount:\n",
    "    print(\"Number of text comments you have retrieved is:\", len(dic_comments), \"(requesting more...)\")\n",
    "    for docID in docket['Document ID']:\n",
    "        comment=\"\"\n",
    "        if docID in dic_comments.keys():\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                request = urllib.request.urlopen(baseURL + docID)\n",
    "                comment = json.loads(request.read())['comment']['value']\n",
    "                dic_comments.update({docID: comment})\n",
    "                time.sleep(0.2)     # Sleep to avoid the Too Many Requests error due to the rate limit set by Regulations.gov\n",
    "            except:\n",
    "                commentsRetrieved = pd.DataFrame(dic_comments, index=[0]).T.reset_index().rename(\n",
    "                    columns={'index': 'Document ID', 0: 'Text Comment'})\n",
    "                commentsRetrieved.to_csv(saveFile, index=False)\n",
    "                time.sleep(60)      # Sleep longer if you have reached the rate limit\n",
    "                pass\n",
    "else:\n",
    "    if len(dic_comments)==commentCount:\n",
    "        print(\"Number of text comments you have retrieved is:\", len(dic_comments), \"(request completed)\")\n",
    "        print(\"END\")\n",
    "textComments = pd.DataFrame(dic_comments,index=[0]).T.reset_index().rename(columns={'index': 'Document ID',0:'Text Comment'})\n",
    "textComments.to_csv(saveFile,index=False)\n",
    "\n",
    "\n",
    "#----------------------------Retrieve comments submitted as PDF or DOC attachments--------------------------------------\n",
    "\n",
    "docket_att=docket[docket[\"Attachment Count\"].notnull()]\n",
    "\n",
    "baseURL1 = \"https://api.data.gov/regulations/v3/download?api_key=\"+APIkey+\"&documentId=\"\n",
    "baseURL2=\"&attachmentNumber=\"\n",
    "baseURL3_pdf=\"&contentType=pdf\"\n",
    "baseURL3_doc=\"&contentType=msw\"\n",
    "\n",
    "folderPath=\"Retrieve Comments/Comment Attachments/\"    #! Specify the path of the folder where you want to save the downloaded files\n",
    "\n",
    "totalAtt=sum(docket_att['Attachment Count'])    # It may take a long time if you are downloading a large number of attachments\n",
    "print(\"Total number of attachments you are requesting to downloaded is:\", totalAtt)\n",
    "downloaded=[]\n",
    "undownloaded=[]\n",
    "attempt=0\n",
    "max_attempt=10    # Define the maximum times you want to loop over the docket metadata file\n",
    "while (len(downloaded)<totalAtt) & (attempt<=max_attempt):\n",
    "    if attempt>1:\n",
    "        print(\"Number of attachments you have downloaded is:\", len(downloaded),\"(downloading more...)\")\n",
    "    for docID in docket_att[\"Document ID\"]:\n",
    "        no=1\n",
    "        attNo = docket_att[docket_att[\"Document ID\"] == docID][\"Attachment Count\"].values[0]\n",
    "        while no <= attNo:\n",
    "            fileName=docID+\"_\"+str(no)\n",
    "            if (os.path.isfile(folderPath+docID+\"_\"+str(no)+\".pdf\")) or (os.path.isfile(folderPath+fileName+\".doc\")):\n",
    "                if fileName not in downloaded:\n",
    "                    downloaded.append(fileName)\n",
    "                pass\n",
    "            else:\n",
    "                try:\n",
    "                    urllib.request.urlretrieve(baseURL1 + docID + baseURL2 + str(no) + baseURL3_pdf, folderPath+fileName+\".pdf\")\n",
    "                    downloaded.append(fileName)\n",
    "                    time.sleep(5)      # Sleep to avoid the Too Many Requests error due to the rate limit set by Regulations.gov\n",
    "                except:\n",
    "                    try:\n",
    "                        urllib.request.urlretrieve(baseURL1 + docID + baseURL2 + str(no) + baseURL3_doc,\n",
    "                                                   folderPath + fileName + \".doc\")\n",
    "                        downloaded.append(fileName)\n",
    "                        time.sleep(5)  # Sleep to avoid the Too Many Requests error due to the rate limit set by Regulations.gov\n",
    "                    except:\n",
    "                        if attempt==max_attempt:\n",
    "                            undownloaded.append(fileName)\n",
    "                        time.sleep(60)  # Sleep longer if you have reached the rate limit\n",
    "                        pass\n",
    "            no=no+1\n",
    "    attempt=attempt+1\n",
    "else:\n",
    "    if len(downloaded)==totalAtt:\n",
    "        print(\"Number of attachments you have downloaded is:\", len(downloaded), \"(downloading completed)\")\n",
    "    else:\n",
    "        print(\"Number of attachments you have downloaded is:\", len(downloaded), \"(downloading incompleted)\")\n",
    "        print(\"Request attempts exceeded \"+str(max_attempt)+\". The following file(s) could not be downloaded:\")\n",
    "        print(undownloaded)\n",
    "        print(\"Note: You need to manually download the attachments not in PDF or DOC format.\")\n",
    "    print(\"END\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274dba51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34f4749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
